```{r message=FALSE, warning=FALSE}
# Insert the function to *tidy up* the code when they are printed out
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

# Load libraries

## Load a set of packages inclusing: broom, cli, crayon, dbplyr , dplyr, dtplyr, forcats,
#googledrive, googlesheets4, ggplot2, haven, hms, httr, jsonlite, lubridate , magrittr, 
#modelr, pillar, purrr, readr, readxl, reprex, rlang, rstudioapi, rvest, stringr, tibble, 
#tidyr, xml2
library(tidyverse)

# Provide a set of estimators for models and (robust) covariance matrices and tests for panel data econometrics, 
library(plm)

## Functions, data sets, examples, demos, and vignettes for the book Christian Kleiber and Achim Zeileis (2008), 
#Applied Econometrics with R
library(AER)

## provides geoms for ggplot2 to repel overlapping text labels.
library(ggrepel)
library(stargazer)
library(gridExtra)
```

```{r load data, echo = FALSE, include=FALSE}
library(data.table)

load(file="~/school/MIDS-271/mids-w271-oliviapratt/homework/lab3/driving.RData", verbose = TRUE)

## please comment these calls in your work 
head(data)
desc
```
```{r add states abbreviations}
states <- read.csv("~/school/MIDS-271/mids-w271-oliviapratt/homework/lab3/states.csv")
states <- cbind(states, row = row_number(states))
states
```

# (30 points, total) Build and Describe the Data 

1. (5 points) Load the data and produce useful features. Specifically: 
    - Produce a new variable, called `speed_limit` that re-encodes the data that is in `sl55`, `sl65`, `sl70`, `sl75`, and `slnone`; 
    
```{r recode speed limit columns}    
data <- data %>%
  mutate(speed_limit =
           case_when(
             data$sl55 > .5 ~ 55,
             data$sl65 > .5 ~ 65,
             data$sl70 > .5 ~ 70,
             data$sl75 > .5 ~ 75,
             data$slnone > .5 ~ 0,
             data$year == 1996 & data$state == 6 ~ 75,
             data$year == 1996 & data$state == 11 ~ 70,
             data$year == 1995 & data$state == 21 ~ 65,
             data$year == 1997 & data$state == 24 ~ 70,
             data$year == 1988 & data$state == 47 ~ 65
           ))

```

    - Produce a new variable, called `year_of_observation` that re-encodes the data that is in `d80`, `d81`, ... , `d04`. 
    
```{r recode year}    
data <- data %>% 
  mutate(year_of_observation =
           case_when(
             data$d80 == 1 ~ 1980,
             data$d81 == 1 ~ 1981,
             data$d82 == 1 ~ 1982,
             data$d83 == 1 ~ 1983,
             data$d84 == 1 ~ 1984,
             data$d85 == 1 ~ 1985,
             data$d86 == 1 ~ 1986,
             data$d87 == 1 ~ 1987,
             data$d88 == 1 ~ 1988,
             data$d89 == 1 ~ 1989,
             data$d90 == 1 ~ 1990,
             data$d91 == 1 ~ 1991,
             data$d92 == 1 ~ 1992,
             data$d93 == 1 ~ 1993,
             data$d94 == 1 ~ 1994,
             data$d95 == 1 ~ 1995,
             data$d96 == 1 ~ 1996,
             data$d97 == 1 ~ 1997,
             data$d98 == 1 ~ 1998,
             data$d99 == 1 ~ 1999,
             data$d00 == 1 ~ 2000,
             data$d01 == 1 ~ 2001,
             data$d02 == 1 ~ 2002,
             data$d03 == 1 ~ 2003,
             data$d04 == 1 ~ 2004,
             TRUE ~ 00000
           )
)
data %>% filter(year_of_observation == 00000)   
```    
    - Produce a new variable for each of the other variables that are one-hot encoded (i.e. `bac*` variable series). 

```{r recode other one-hot vars}
data <- data %>%
  mutate(
    blood_alc =
      case_when(
        bac10 > .5 ~ .1,
        bac08 > .5 ~ .08,
        bac08 == 0 & bac10 == 0 ~ 0,
        bac10 > bac08 ~ .1,
        TRUE ~ .08
      )
  )

```

    - Rename these variables to sensible names that are legible to a reader of your analysis. For example, the dependent variable as provided is called, `totfatrte`. Pick something more sensible, like, `total_fatalities_rate`. There are few enough of these variables to change, that you should change them for all the variables in the data. (You will thank yourself later.)

```{r rename columns}    
old_names <- c("seatbelt", "minage", "zerotol", "gdl", "perse", "totfat",
               "nghtfat", "wkndfat", "totfatpvm", "nghtfatpvm", "wkndfatpvm",
               "statepop", "totfatrte", "nghtfatrte", "wkndfatrte", "vehicmiles",
               "unem", "perc14_24", "vehicmilespc", "sbprim")

new_names <- c("seatbelt_law", "min_drink_age", "zero_tol", "grad_driver_license", "per_se",
               "tot_fat", "tot_night_fat", "tot_wknd_fat", "tot_fat_per_mil_miles",
               "tot_nght_fat_per_mil_miles", "tot_wknd_fat_per_mil_miles",
               "state_pop", "total_fatalities_rate", "tot_nght_fat_rate", "tot_wknd_fat_rate",
               "miles_traveled_b", "unemployment", "percent_pop_14_24", "vehic_miles_pc", "primary_seatbelt")

data <- data %>%
  setnames(old = old_names, new = new_names)
```

```{r select columns}
data <- data %>%
  dplyr::select("year", "state", "seatbelt_law", "min_drink_age", "zero_tol",
         "grad_driver_license", "per_se", "tot_fat", "tot_night_fat", "tot_wknd_fat",
         "tot_fat_per_mil_miles","tot_nght_fat_per_mil_miles", "tot_wknd_fat_per_mil_miles",
         "state_pop", "total_fatalities_rate", "tot_nght_fat_rate", "tot_wknd_fat_rate",
         "miles_traveled_b", "unemployment", "percent_pop_14_24", "vehic_miles_pc",
         "speed_limit", "year_of_observation", "blood_alc", "primary_seatbelt" )
data <- merge(x = data, y = states, by.x = "state", by.y = "row")

data
```
2. (5 points) Provide a description of the basic structure of the dataset. What is this data? How, where, and when is it collected? Is the data generated through a survey or some other method? Is the data that is presented a sample from the population, or is it a *census* that represents the entire population? Minimally, this should include:
    - How is the our dependent variable of interest `total_fatalities_rate` defined? 
    
> The long-panel data being reviewed here has `r ncol(data)` columns and `r nrow(data)` row, where each row is returning metrics having to do with traffic incidents in each state (excluding Alaska and Hawaii) from the years 1980 through 2004, at an annual granularity. Specifically, we will be focusing on traffic fatalities in each state to see if regulations like blood alcohol limits, speed limits, and so on appear to impact the rate of fatalities per state. The rate of fatalities is calculated as the number of fatalities per 100,000 people. This dataset also includes columns that show how many of these fatalities happened while driving at night or on the weekend. 
    
3. (20 points) Conduct a very thorough EDA, which should include both graphical and tabular techniques, on the dataset, including both the dependent variable `total_fatalities_rate` and the potential explanatory variables. Minimally, this should include: 
    - How is the our dependent variable of interest `total_fatalities_rate` defined? 
    - What is the average of `total_fatalities_rate` in each of the years in the time period covered in this dataset? 

```{r}
data %>% 
  dplyr::select(year, state) %>%
  table()
```
```{r}
data %>%
  is.pconsecutive()

pdim(data)
```

```{r,warning=FALSE, echo=FALSE, fig.height=6, fig.width=12}
p6<- data %>%
  filter(as.integer(state) <= 14 ) %>%
  ggplot(aes(x = year, y = total_fatalities_rate)) +
  geom_line() +
  facet_wrap(~ Abbreviation, nrow = 3) +
  labs(x = "Year",  y = "Fatality rate") +
  theme(legend.position = "none") +
  scale_x_continuous(breaks=c(1980, 1990, 2000))

p7<-data %>%
  filter(as.integer(state) > 14 & as.integer(state) <= 26 ) %>%
  ggplot(aes(x = year, y = total_fatalities_rate)) +
  geom_line() +
  facet_wrap(~ Abbreviation, nrow = 3)+
  labs(x = "Year",  y = "Fatality rate") +
  theme(legend.position = "none")+
  scale_x_continuous(breaks=c(1980, 1990, 2000))

p8<-data %>%
  filter(as.integer(state) > 26 &as.integer(state) <= 38 ) %>%
  ggplot(aes(x = year, y = total_fatalities_rate)) +
  geom_line() +
  facet_wrap(~ Abbreviation, nrow = 3)+
  labs(x = "Year",  y = "Fatality rate") +
  theme(legend.position = "none")+
  scale_x_continuous(breaks=c(1980, 1990, 2000))

p9<- data %>%
  filter(as.integer(state) > 38 ) %>%
  ggplot(aes(x =year, y = total_fatalities_rate)) +
  geom_line()+
  facet_wrap(~ Abbreviation, nrow = 3)+
  labs(x = "Year",  y = "Fatality rate") +
  theme(legend.position = "none")+
  scale_x_continuous(breaks=c(1980, 1990, 2000))


grid.arrange(p6,p7,p8, p9, nrow = 2, ncol = 2)
```

```{r}
mean_fat <- data %>%
  group_by(year) %>%
  summarise(mean = mean(total_fatalities_rate))

plot(mean_fat, type = "l", xlab = "Year", ylab = "Mean", main = "Average Fatality Rate from 1980 - 2004") 
```

```{r,warning=FALSE,echo=FALSE, fig.height=6, fig.width=12}

p2<- data %>%
  filter(as.integer(state) <= 12 ) %>%
  ggplot(aes(x = year, y = total_fatalities_rate)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) <= 12  & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p3<- data %>%
   filter(as.integer(state) > 12 & as.integer(state) <= 24 ) %>%
  ggplot(aes(x = year, y = total_fatalities_rate)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) > 12 & as.integer(state) <= 24  & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p4<- data %>%
  filter(as.integer(state) > 24 &as.integer(state) <= 36 ) %>%
  ggplot(aes(x = year, y = total_fatalities_rate)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) > 24 &as.integer(state) <= 36 & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p5<- data %>%
  filter(as.integer(state) > 36 ) %>%
  ggplot(aes(x = year, y = total_fatalities_rate)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate") +
  geom_label_repel(data = filter(data, as.integer(state) > 36 & year == 1984),aes(label = Abbreviation),
                   nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

grid.arrange(p2,p3,p4, p5, nrow = 2, ncol = 2)
```

```{r}
all_means <- data %>%
  group_by(year) %>%
  summarise(avg_total_fatality_rate = mean(total_fatalities_rate), avg_drinking_age = mean(min_drink_age),
            avg_pop = mean(state_pop), avg_unemployment = mean(unemployment), avg_perc_pop = mean(`percent_pop_14_24`),
            avg_speed_limit = mean(speed_limit), avg_blood_alc_limit = mean(blood_alc))

all_means %>%
  ggplot(aes(x = year)) +
  # geom_line(aes(x=year, y=avg_total_fatality_rate)) +
   geom_line(aes(x=year, y=avg_drinking_age)) +
  # geom_line(aes(x=year, y=avg_unemployment)) +
   geom_line(aes(x=year, y=avg_perc_pop, color="red")) 
  # geom_line(aes(x=year, y=avg_speed_limit)) 
  # geom_line(aes(x=year, y=avg_blood_alc_limit, color="red"))
```

```{r,warning=FALSE,echo=FALSE, fig.height=6, fig.width=12}

p2<- data %>%
  filter(as.integer(state) <= 12 ) %>%
  ggplot(aes(x = year, y = miles_traveled_b)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) <= 12  & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p3<- data %>%
   filter(as.integer(state) > 12 & as.integer(state) <= 24 ) %>%
  ggplot(aes(x = year, y = miles_traveled_b)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) > 12 & as.integer(state) <= 24  & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p4<- data %>%
  filter(as.integer(state) > 24 &as.integer(state) <= 36 ) %>%
  ggplot(aes(x = year, y = miles_traveled_b)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) > 24 &as.integer(state) <= 36 & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p5<- data %>%
  filter(as.integer(state) > 36 ) %>%
  ggplot(aes(x = year, y = miles_traveled_b)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate") +
  geom_label_repel(data = filter(data, as.integer(state) > 36 & year == 1984),aes(label = Abbreviation),
                   nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

grid.arrange(p2,p3,p4, p5, nrow = 2, ncol = 2)
```

```{r,warning=FALSE,echo=FALSE, fig.height=6, fig.width=12}

p2<- data %>%
  filter(as.integer(state) <= 12 ) %>%
  ggplot(aes(x = year, y = `percent_pop_14_24`)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) <= 12  & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p3<- data %>%
   filter(as.integer(state) > 12 & as.integer(state) <= 24 ) %>%
  ggplot(aes(x = year, y = `percent_pop_14_24`)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) > 12 & as.integer(state) <= 24  & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p4<- data %>%
  filter(as.integer(state) > 24 &as.integer(state) <= 36 ) %>%
  ggplot(aes(x = year, y = `percent_pop_14_24`)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate")+
  geom_label_repel(data = filter(data, as.integer(state) > 24 &as.integer(state) <= 36 & year == 1984),
                   aes(label = Abbreviation), nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

p5<- data %>%
  filter(as.integer(state) > 36 ) %>%
  ggplot(aes(x = year, y = `percent_pop_14_24`)) +
  geom_line(aes(color = Abbreviation)) +
  labs(x = "Year",  y = "Fatality rate") +
  geom_label_repel(data = filter(data, as.integer(state) > 36 & year == 1984),aes(label = Abbreviation),
                   nudge_x = .75,na.rm = TRUE) +
  theme(legend.position = "none")

grid.arrange(p2,p3,p4, p5, nrow = 2, ncol = 2)
```

```{r,warning=FALSE, echo=FALSE, fig.height=6, fig.width=12}
p6<- data %>%
  filter(as.integer(state) <= 14 ) %>%
  ggplot(aes(x = year, y = `percent_pop_14_24`)) +
  geom_line() +
  facet_wrap(~ Abbreviation, nrow = 3) +
  labs(x = "Year",  y = "Fatality rate") +
  theme(legend.position = "none") +
  scale_x_continuous(breaks=c(1980, 1990, 2000))

p7<-data %>%
  filter(as.integer(state) > 14 & as.integer(state) <= 26 ) %>%
  ggplot(aes(x = year, y = `percent_pop_14_24`)) +
  geom_line() +
  facet_wrap(~ Abbreviation, nrow = 3)+
  labs(x = "Year",  y = "Fatality rate") +
  theme(legend.position = "none")+
  scale_x_continuous(breaks=c(1980, 1990, 2000))

p8<-data %>%
  filter(as.integer(state) > 26 &as.integer(state) <= 38 ) %>%
  ggplot(aes(x = year, y = `percent_pop_14_24`)) +
  geom_line() +
  facet_wrap(~ Abbreviation, nrow = 3)+
  labs(x = "Year",  y = "Fatality rate") +
  theme(legend.position = "none")+
  scale_x_continuous(breaks=c(1980, 1990, 2000))

p9<- data %>%
  filter(as.integer(state) > 38 ) %>%
  ggplot(aes(x =year, y = `percent_pop_14_24`)) +
  geom_line()+
  facet_wrap(~ Abbreviation, nrow = 3)+
  labs(x = "Year",  y = "Fatality rate") +
  theme(legend.position = "none")+
  scale_x_continuous(breaks=c(1980, 1990, 2000))


grid.arrange(p6,p7,p8, p9, nrow = 2, ncol = 2)
```

```{r,warning=FALSE, echo=FALSE, fig.height=6, fig.width=12}
data %>%
  group_by(Abbreviation) %>%
  ggplot(aes(x = reorder(Abbreviation,total_fatalities_rate), y = total_fatalities_rate)) +
  geom_boxplot() +
  labs(x = "States",  y = "Fatality rate")

data %>%
  group_by(Abbreviation) %>%
  ggplot(aes(x = reorder(Abbreviation,total_fatalities_rate), y = `percent_pop_14_24`)) +
  geom_boxplot() +
  labs(x = "States",  y = "Percent pop 14-24")

data %>%
  group_by(Abbreviation) %>%
  ggplot(aes(x = reorder(Abbreviation,total_fatalities_rate), y = min_drink_age)) +
  geom_boxplot() +
  labs(x = "States",  y = "Min Drinking Age")

data %>%
  group_by(Abbreviation) %>%
  ggplot(aes(x = reorder(Abbreviation,total_fatalities_rate), y = unemployment)) +
  geom_boxplot() +
  labs(x = "States",  y = "Unemployment Rate")

data %>%
  group_by(Abbreviation) %>%
  ggplot(aes(x = reorder(Abbreviation,total_fatalities_rate), y = blood_alc)) +
  geom_boxplot() +
  labs(x = "States",  y = "Unemployment Rate")
```

```{r,warning=FALSE, echo=FALSE, fig.height=6, fig.width=12}
p18<- data %>%
  filter(as.integer(state) <= 14 ) %>%
  ggplot(aes(x = `percent_pop_14_24`, y = total_fatalities_rate)) +
  geom_point() +
  facet_wrap(~ Abbreviation, nrow = 3,scales = "free") +
  labs(x = "Percent of Pop. between 14-24",  y = "Fatality rate")

p19<- data %>%
  filter(as.integer(state) > 14 & as.integer(state) <= 26 ) %>%
  ggplot(aes(x = `percent_pop_14_24`, y = total_fatalities_rate)) +
  geom_point() +
  facet_wrap(~ Abbreviation, nrow = 3,scales = "free")+
  labs(x = "Percent of Pop. between 14-24",  y = "Fatality rate")

p20<- data %>%
  filter(as.integer(state) > 26 &as.integer(state) <= 38 ) %>%
  ggplot(aes(x = `percent_pop_14_24`, y = total_fatalities_rate)) +
  geom_point() +
  facet_wrap(~ Abbreviation, nrow = 3,scales = "free")+
  labs(x = "Percent of Pop. between 14-24",  y = "Fatality rate")

p21<- data %>%
  filter(as.integer(state) > 38 ) %>%
  ggplot(aes(x = `percent_pop_14_24`, y = total_fatalities_rate)) +
  geom_point()+
  facet_wrap(~ Abbreviation, nrow = 3,scales = "free")+
  labs(x = "Percent of Pop. between 14-24",  y = "Fatality rate")

grid.arrange(p18,p19,p20, p21, nrow = 2, ncol = 2)
```

```{r}
within.model <- plm(total_fatalities_rate ~ year + 
                                              blood_alc +
                                              per_se + 
                                              primary_seatbelt + 
                                              speed_limit + 
                                              grad_driver_license +               
                                              log(`percent_pop_14_24`) + 
                                              log(unemployment) + 
                                              log(vehic_miles_pc), 
                data = data, index=c("state", "year"), model="within")


pool.model <- plm(total_fatalities_rate ~ year + 
                                              blood_alc +
                                              per_se + 
                                              primary_seatbelt +  
                                              speed_limit + 
                                              grad_driver_license +               
                                              log(`percent_pop_14_24`) + 
                                              log(unemployment) + 
                                              log(vehic_miles_pc), 
                data = data, index=c("state", "year"), model="pooling")

fd.model <- plm(total_fatalities_rate ~ year + 
                                              blood_alc +
                                              per_se + 
                                              primary_seatbelt +  
                                              speed_limit + 
                                              grad_driver_license +               
                                              log(`percent_pop_14_24`) + 
                                              log(unemployment) + 
                                              log(vehic_miles_pc), 
                data = data, index=c("state", "year"), model="fd")

between.model <- plm(total_fatalities_rate ~ year + 
                                              blood_alc +
                                              per_se + 
                                              primary_seatbelt + 
                                              speed_limit + 
                                              grad_driver_license +               
                                              log(`percent_pop_14_24`) + 
                                              log(unemployment) + 
                                              log(vehic_miles_pc), 
                data = data, index=c("state", "year"), model="between")

random.model <- plm(total_fatalities_rate ~ year + 
                                              blood_alc +
                                              per_se + 
                                              primary_seatbelt +  
                                              speed_limit + 
                                              grad_driver_license +               
                                              log(`percent_pop_14_24`) + 
                                              log(unemployment) + 
                                              log(vehic_miles_pc), 
                data = data, index=c("state", "year"), model="random")


stargazer(pool.model, fd.model, between.model, within.model, random.model, type = "text",
          omit.stat = c("ser","f","adj.rsq"), dep.var.labels = "",
          column.labels = c("Pooled", "FD", "Between", "Within", "Random"))
```

```{r}
pFtest(within.model, pool.model)
```
Our pFtest returns a significant p value, meaning that we reject the null hypothesis. We should include the state and time fixed effects in our model.

```{r}
pwfdtest(fd.model, data=data, index=c("state", "year"), h0="fe")
```
```{r}
pwfdtest(fd.model, data=data, index=c("state", "year"), h0="fd")

```

```{r}
phtest(within.model, random.model)

```

- What do you estimate for coefficients on the blood alcohol variables? How do 
the coefficients on the blood alcohol variables change, if at all? 

> The fixed effect model estimates that blood alcohol has a coefficient of -6.163. In action, this means that for a unit increase in blood alcohol limit, the fatality rate will decrease by approximately 6 fatalities per 100,000 people. However in our case, blood alcohol is measured in hundreths and tenths rather than in unitary increments, so a full unit increase isn't likely to take place. In the Pooled model, the coefficient for blood alcohol is -8.736, which is the largest impact out of the five models. The coefficient for the First Difference model is -3.092, the smallest impact of the models. The between model has a similar coefficient of -3.313, and lastly the Random Effects model has a coefficient of -6.610, very simlilar to the Fixed Effect Model. All of these coefficients are significant.

- What do you estimate for coefficients on per se laws? How do the coefficients 
on per se laws change, if at all? 

> The Fixed Effect model estimates that the coefficient for the per-se parameter is -1.219. In our data, the per se parameter is a one-hot-encoded variable with some values being between zero and one, in cases where states took on the law mid-year. In the case where a state does have per se laws in a given year, our model estimates that the rate of fatalities will decrease by 1.2 per 100,000 people. The is the largest impact of the five models, with the coefficients of the Pooled Effect, First Difference, Between, and Random Effect being -0.881, -0.669, -0.467, and -1.178 respectively. All of these coefficients are significant.

- What do you estimate for coefficients on primary seat-belt laws? How do the 
coefficients on primary seatbelt laws change, if at all? 

> The primary seat belt law variable is also a Boolean, indicating whether a state uses primary seat belt laws or secondary. For the Pooled model, the coefficient is not significant and is -0.322, a fairly small impact. Similarly, the coefficient for the First Difference model is -0.201, and the coefficient for the Between model is -0.491. This variable is not significant in either model. However, the coefficients for both the Fixed Effect and Random Effect models are both significant, being -0.867 and -0.833 respectively. 

Which set of estimates do you think is more reliable? Why do you think this? 

> The Wooldridge first-difference test for serial correlation in panels returns significant p values for both the Fixed Effect (within) and First Difference models, however the p value for the Fixed Effect model is far more significant. This leads us to believe that the Fixed Effect model is more reliable than the First Difference and Pooled models. Moving on, the outcome of the Hausmen test is not significant, meaning we do not reject the null hypothesis that random effects are appropriate, suggesting that we should not use the Fixed Effect model. Because of these outcomes, the estimates created by the Random Effects model will be the most reliable.

- What assumptions are needed in each of these models?  

* For each 'i' the model is 
$y_{it} = \beta_1 x_{it1} + ... + \beta_k x_{itk} + a_i + u_{it}, t =1 ..T$.
* We have a random sample from the cross section.
* Each explanatory variable changes over time (for at least some time) and no 
perfect linear relationship exists between explanatory variables.
* For each t, the expected value of the idiosyncratic error given the explanatory
variables in all time periods and the unobserved effect is zero: $E(u_{it}|X_i, a_i)=0$.
* The variance of the difference errors, conditional on all explanatory variables, is constant $Var(\triangle u_{it} | X_i) = \sigma^2_u, t=2,....,T$. This is required for homoskedastic errors.
* For all $t \neq s$, the differences in the idiosyncratic errors are 
uncorrelated (conditional on all explanatory variables). This is for serially 
uncorrelated residuals.
 
- Are these assumptions reasonable in the current context?

> The assumption in an pooled OLS model is that the data is IID. Here in the 
data set, a sample of a large population is collected on different years. It is 
unlikely that a particular individual sample data point is measured twice. In 
such a circumstance a pooled OLS model would be applicable. 
> However, in this data set, data granularity is at the state level and the same 
state is measured multiple times across years. This violates the assumption of 
IID in the pooled OLS. 
> A fixed effect model is then expected to be a better model in this scenario. 
We perform a F-test between the pooled and the fixed effect model to check for 
fixed effects. The null hypothesis is that there are no fixed effects and the 
alternate hypothesis is that there are fixed effects. We test against an alpha 
of 0.05.
